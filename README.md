# Интеграция инструментов для управления данными, экспериментами и автоматизацией в ML-проектах (DVC, MLflow, ClearML)

# Описание проекта: 
В данном проекте будет выполнена интеграция трех ключевых инструментов для построения полного цикла машинного обучения: DVC для управления данными, MLflow для управления экспериментами, и ClearML для автоматизации процессов. Основная цель проекта — обеспечить возможность хранения, обработки данных, проведения экспериментов, сравнения моделей и автоматизации всех этапов работы с данными и моделями с помощью CI/CD, экспериментов и пайплайнов.

# Цель проекта: 
Познакомиться с основами управления данными, экспериментами и автоматизации ML-процессов, а также интегрировать инструменты DVC, MLflow и ClearML для эффективного построения ML-пайплайнов.

# Задачи проекта:

**Часть 1: Управление данными с DVC**

* Использовать DVC для добавления данных в проект.
* Настроить удаленное хранилище (например, Google Drive, AWS S3).
* Создать и запустить пайплайн для обработки данных.
* Интегрировать DVC в CI/CD для автоматической обработки данных.

**Часть 2: Управление экспериментами с MLflow**

* Настроить MLflow для управления экспериментами.
* Провести как минимум два эксперимента с разными параметрами.
* Сравнить модели с помощью MLflow по меткам и меткам.
* Составить отчет с результатами экспериментов.

**Часть 3: Автоматизация экспериментов с ClearML**

* Настроить сервер ClearML и интегрировать его с проектом.
* Создать автоматизированный пайплайн для запуска экспериментов.
* Запускать пайплайн через ClearML для корректной обработки данных и запуска экспериментов.
* Сравнивать результаты и составить отчет.





# Анализ экспериментов по MLflow

## Введение

В рамках данного исследования была проведена серия экспериментов с целью оценки производительности моделей машинного обучения. В частности, рассматривалась логистическая регрессия, применяемая к стандартному набору данных Iris. Основное внимание уделялось влиянию различных параметров регуляризации и алгоритмов оптимизации на качество модели и время её обучения.

## Описание данных

Для экспериментов использовался датасет Iris, который является классическим примером данных для задач классификации. Он содержит 150 экземпляров цветов ириса, принадлежащих к трём видам. В качестве входных данных используются четыре признака: длина и ширина лепестка, длина и ширина чашелистика. Данные были загружены и обработаны с использованием вспомогательных скриптов `download.py` и `process_data.py`, в которых производилось их считывание и приведение к необходимому формату.

## Настройка экспериментов

Эксперименты проводились с использованием платформы MLflow для управления логами и метриками. В ходе тестирования были рассмотрены две конфигурации модели логистической регрессии с различными значениями параметра регуляризации `C` и алгоритма оптимизации `solver`.

## Проведённые эксперименты

| Эксперимент | C   | Solver    | Точность (accuracy) | Время обучения |
|------------|-----|-----------|---------------------|---------------|
| 1          | 0.1 | liblinear | 1.0                 | 2.8 секунды   |
| 2          | 1.0 | lbfgs     | 0.8444              | 9.0 секунд    |

## Сравнительный анализ моделей

### Оценка точности

Анализ результатов показал, что модель с параметрами `C=0.1` и `solver='liblinear'` продемонстрировала более высокую точность классификации (**1.0**) по сравнению с моделью `C=1.0` и `solver='lbfgs'`, у которой точность составила **0.8444**. Это может быть связано с тем, что более сильная регуляризация (`C=0.1`) помогла модели лучше обобщать данные.

### Временные характеристики

Существенное различие наблюдается во времени обучения. Вариант с `solver='lbfgs'` требовал **9 секунд**, что более чем в три раза дольше, чем **2.8 секунды** у `solver='liblinear'`. Это может объясняться спецификой работы оптимизаторов: `lbfgs` предназначен для больших наборов данных и требует больше времени на итерации.

### Итоговые выводы

На основании полученных результатов можно сделать следующие заключения:

- **Первая модель (C=0.1, solver='liblinear')** превосходит вторую по точности.
- **Время обучения** первой модели существенно ниже, что делает её более предпочтительной с точки зрения вычислительной эффективности.
- **Более слабая регуляризация (C=1.0)** в эксперименте 2, возможно, привела к переобучению модели, что ухудшило её качество.

## Рекомендации и возможные направления исследований

- Провести дополнительные эксперименты с другими значениями `C`, чтобы определить оптимальный баланс между обобщающей способностью и точностью модели.
- Включить дополнительные метрики, такие как `precision`, `recall` и `F1-score`, чтобы глубже проанализировать работу модели.
- Исследовать влияние других алгоритмов оптимизации (`newton-cg`, `sag`, `saga`) на производительность модели.
- Рассмотреть возможность применения методов предварительной обработки данных, таких как нормализация признаков, что может повлиять на сходимость оптимизационного процесса.
- Для больших объемов данных протестировать `solver='lbfgs'` с меньшими значениями `C`, чтобы проверить влияние гиперпараметров на скорость и качество обучения.

## Заключение

Проведённый анализ продемонстрировал важность правильного выбора гиперпараметров и алгоритмов оптимизации при обучении моделей машинного обучения. Полученные результаты позволили сделать вывод о том, что модель с `C=0.1` и `solver='liblinear'` является наиболее эффективной для данной задачи, обеспечивая наилучшее сочетание точности и скорости обучения. Однако дальнейшие исследования и тестирование на более сложных данных могут выявить дополнительные закономерности, требующие оптимизации модели.

## Приложения

Проведенные эксперименты

![Скриншот MLflow UI](https://github.com/Serafim-25/hw2_zagorodniyss/blob/main/screens/MLflow(1).png)

Эксперимент №1

![Скриншот MLflow UI](https://github.com/Serafim-25/hw2_zagorodniyss/blob/main/screens/MLflow(2).png)

Эксперимент №2

![Скриншот MLflow UI](https://github.com/Serafim-25/hw2_zagorodniyss/blob/main/screens/MLflow(3).png)






# Автоматизация ML-экспериментов с использованием ClearML

## Введение

В рамках данного исследования была разработана и протестирована система автоматизированных ML-экспериментов на основе ClearML. Основной целью работы являлось создание пайплайна для подготовки данных, обучения моделей и анализа их производительности, что позволило упростить процесс повторяемости экспериментов и снизить влияние человеческого фактора.

Исследование проводилось на классическом наборе данных Iris, а в качестве модели использовалась логистическая регрессия. Основное внимание уделялось влиянию параметров регуляризации `C` и выбора алгоритма оптимизации `solver` на качество модели.

## Настройка окружения и интеграция с ClearML

Для реализации экспериментов была развернута система ClearML, обеспечивающая автоматизированный мониторинг экспериментов, сохранение логов и воспроизводимость результатов. Также использовался DVC (Data Version Control) для управления данными и их предобработкой.

Основные этапы настройки:

* Подключение ClearML и регистрация проекта в веб-интерфейсе.

* Настройка логирования экспериментов и автоматической записи параметров моделей.

* Интеграция с DVC для управления версиями данных.

## Реализация ML-пайплайна

В ходе экспериментов мы использовали **ClearML Pipelines**, чтобы автоматизировать ключевые этапы машинного обучения. Наш пайплайн включает следующие шаги:

1. **Загрузка данных (`download_data`)**  
   - Получение исходного датасета Iris.
   
2. **Предобработка данных (`process_data`)**  
   - Очистка и приведение данных к нужному формату.
   
3. **Обучение модели (`train_model`)**  
   - Запуск экспериментов с разными гиперпараметрами.
   - Логирование метрик в ClearML.
   
4. **Версионирование данных с DVC (`dvc_pull`, `dvc_repro`, `dvc_push`)**  
   - Управление изменениями данных и моделей.

Каждый этап интегрирован с ClearML, что позволяет не только управлять экспериментацией, но и вносить изменения в реальном времени, отслеживая прогресс моделей через веб-интерфейс.

## Проведённые эксперименты

В рамках исследования мы провели два эксперимента, в которых изменяли параметры регуляризации `C` и алгоритма оптимизации `solver` в **логистической регрессии**.

### Результаты экспериментов

| Эксперимент | C   | Solver    | Accuracy |
|------------|-----|-----------|----------|
| 1          | 0.1 | liblinear | 0.95     |
| 2          | 1.0 | lbfgs     | 0.97     |

### Анализ результатов

1. **Качество моделей:**  
   - Вторая модель (`C=1.0, solver='lbfgs'`) показала наибольшую точность (0.97), что говорит о лучшем соответствии модели данным. 
   - Первая модель (`C=0.1, solver='liblinear'`) продемонстрировала несколько меньшую точность (0.95), однако такая разница не является критичной.

2. **Регуляризация:**  
   - Более слабая регуляризация (больший `C`) позволила второй модели лучше подстроиться под данные, что повысило точность.
   - Модель с `C=0.1` имела большую степень регуляризации, что могло ограничивать ее способность обучаться на сложных зависимостях.
  
3. **Выбор алгоритма оптимизации:**  
   - `liblinear` подходит для небольших наборов данных, однако в данном случае он уступил `lbfgs`.
   - `lbfgs` хорошо работает с многомерными данными, что, вероятно, привело к его лучшей производительности.
  
### Визуализация и логирование

В ходе экспериментов все результаты логировались в ClearML, что позволило:

* Отслеживать динамику метрик.
* Сравнивать производительность моделей в едином веб-интерфейсе.
* Анализировать влияние гиперпараметров на итоговую точность.

Скриншот интерфейса ClearML с результатами экспериментов представлен ниже в приложении.
     
### Выводы и рекомендации

На основе проведенного анализа можно сделать следующие выводы:

* Модель с `C=1.0` и `solver='lbfgs'` продемонстрировала лучшие результаты на данных Iris, обеспечивая точность 0.97.
* Оптимальный выбор параметров регуляризации (`C`) играет ключевую роль в качестве модели. Более высокие значения `C` могут приводить к переобучению, но в данном случае это дало позитивный эффект.
* Выбор алгоритма оптимизации также влияет на результат. `lbfgs` показал себя лучше на данном наборе данных.
* Использование ClearML значительно упростило процесс мониторинга экспериментов и позволило быстро анализировать изменения в гиперпараметрах.

### Возможные направления дальнейшей работы

1. Исследование других алгоритмов оптимизации:

* `newton-cg`, `sag`, `saga` могут дать более высокую точность или снизить время обучения.

2. Дополнительные эксперименты с регуляризацией:

* Тестирование значений `C` в диапазоне `[0.01, 10]` поможет найти оптимальный баланс между переобучением и недообучением.

3. Использование других моделей:

* Протестировать SVM, Random Forest или нейронные сети, чтобы оценить их эффективность на этом датасете.

4. Автоматизация поиска гиперпараметров:

* Подключение гиперпараметрического поиска (например, Optuna) в связке с ClearML для автоматического подбора `C` и `solver`.

## Заключение

Данный проект показал, что автоматизация экспериментов с ClearML позволяет значительно ускорить процессы машинного обучения, облегчает мониторинг экспериментов и обеспечивает воспроизводимость результатов. Применение логистической регрессии с `C=1.0` и `solver='lbfgs'` дало лучший результат, однако дальнейшие исследования могут выявить ещё более оптимальные конфигурации. ClearML продемонстрировал свою эффективность как инструмент управления экспериментами и логирования, что делает его полезным для работы с более сложными задачами машинного обучения.

## Приложения

Для удобства анализа был использован **ClearML UI**, где можно отслеживать динамику метрик и сравнивать модели.

![Скриншот MLflow UI](https://github.com/Serafim-25/hw2_zagorodniyss/blob/main/screens/ClearML.png)
